# 简介
我的项目是把大量的合同pdf文件先解析存到本地，然后分段一方面提取关键词比如人名日期什么的
存到关系数据库，还要把关键词存到elasticsearch做关键词搜索，一方面调用embeddind模型存到
向量数据库，然后根据用户的输入去检索返回，比如“给我所有张三签署的合同”，“给我所有2023年1月
至2025年3月某某公司的合同”，“给我关于某个合同的交付信息”等等
# 数据层
加载-解析-清洗-结构化提取-存入postgresql
            -嵌入-存入milvus(标量+向量)
            -存储关键词到elasticsearch(标量+分段文本及关键词)
# 检索
意图识别 + 结构化过滤
## 分析
LLM提取结构化过滤条件
用户 Query: “给我2023年张三签署的关于服务器采购的合同交付信息”
```json
{
  "intent": "hybrid_search", // 意图：混合搜索
  "sql_filters": {
     "party_name": "张三",
     "date_range": {"start": "2023-01-01", "end": "2023-12-31"}
  },
  "semantic_query": "服务器采购交付信息", // 用于向量搜索
  "keywords": ["服务器", "采购", "交付"] // 用于 ES 搜索
}
```
## 分发检索
根据解析出来的 JSON，代码逻辑走不同的分支：
### 纯结构化查询
* Query: "张三签了多少份合同？" / "列出所有2024年的合同"
* Action: 如果有甲乙方信息则先用es过滤再查询 PostgreSQL。
* Result: 直接返回 SQL 统计结果，无需向量检索，速度最快，100% 准确。

### 混合查询
* Query: "2023年张三的服务器采购合同交付条款"
* Action:

**Milvus (HNSW 图索引 + 标量过滤)**

Milvus 维护了标量索引（如 `party_a`, `sign_date` 的 Inverted Index）和向量索引（HNSW 图）。
在执行带 expr 过滤的向量搜索时：

```
Query: embedding("服务器采购交付条款") + expr="party_a == '张三' && sign_date >= 1672531200"

执行流程：
1. 遍历 HNSW 图时，对每个访问的节点：
   - 检查该节点对应记录的标量字段是否符合 expr
   - 如果不符合 → 立即剪枝，跳过该分支
   - 如果符合 → 计算向量距离，继续遍历邻居节点
2. 逐层向下，重复上述过程
3. 返回相似度最高的 TopK 结果
```

**关键优化**：
- 标量过滤和向量检索**同步进行**，不是两阶段独立查询
- 在图遍历过程中即时剪枝，避免无效的向量距离计算
- 充分利用 HNSW 图索引的"小世界特性"快速收敛

**ES (倒排索引 + BM25 + 标量过滤)**

ES 维护了 `content` 字段的倒排索引（带 ik_max_word 分词）和标量字段的索引。

```
Query: match(content, "服务器 采购") + filter(party_a: "张三", sign_date: [2023-01-01, 2023-12-31])

执行流程：
1. 使用倒排索引快速定位包含"服务器"、"采购"的文档集合
2. 同时应用标量过滤条件缩小范围
3. 在交集上计算 BM25 分数
4. 返回 TopK 结果
```
## 重排序
将向量化和ES结果合并重排比较（因为不能直接比较）
数量 >= 20 归一化加权粗排
数量 < 20 reranker精排
## 生成
LLM整合生成

chatflow搭建：
## Chain
## Graph

ollama

# 优化 todo

1. Async Indexer（异步索引） 管道
文档解析、分块、Embedding 向量化的并行处理，配合 Go 协程池+任务队列优化 

2. 数据库一致性，但不是强一致性场景
kafka
cdc
3. 监控

4. 记忆/缓存

5. 解析
go原生
go调用py，grpc + unix socket, py预热， 异步解析+队列

query -> ocr -> 

